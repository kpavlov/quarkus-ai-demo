quarkus.application.name=ai-server

# We are doing this so that we can run the jar file directly using `jbang org.acme:weather:1.0.0-SNAPSHOT:runner`
#quarkus.package.jar.type=uber-jar
quarkus.package.jar.type=fast-jar
quarkus.native.builder-image=quay.io/quarkus/ubi-quarkus-native-image:23.1.0.Final

quarkus.langchain4j.openai.chat-model.model-name=gpt-4.1-nano
quarkus.langchain4j.openai.chat-model.max-tokens=500

quarkus.langchain4j.mcp.generate-tool-provider=true
quarkus.langchain4j.mcp.github.transport-type=stdio
quarkus.langchain4j.mcp.github.command=npm,exec,@modelcontextprotocol/server-github
quarkus.langchain4j.mcp.github.environment.GITHUB_PERSONAL_ACCESS_TOKEN=<YOUR_TOKEN>


# Enable logging to a file
#quarkus.log.file.enable=true
#quarkus.log.file.path=ai-server.log
